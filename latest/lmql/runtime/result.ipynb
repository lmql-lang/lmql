{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from lmql.runtime.openai_integration import SequenceResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': {'1': 1, '2': 2}}\n"
     ]
    }
   ],
   "source": [
    "a = {\"k\": {\n",
    "    \"1\": 1\n",
    "}}\n",
    "b = {\"k\": {\n",
    "    \"2\": 2\n",
    "}}\n",
    "\n",
    "def deep_merge(a, b):\n",
    "    for k,v in b.items():\n",
    "        if k in a and isinstance(a[k], dict) and isinstance(b[k], dict):\n",
    "            deep_merge(a[k], b[k])\n",
    "        else:\n",
    "            a[k] = b[k]\n",
    "    return a\n",
    "\n",
    "print(deep_merge(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6XUBW3t50Lsy6IUdthIFYT04SXwMW at 0x7fad382f7ea0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": {\n",
       "        \"text_offset\": [\n",
       "          0,\n",
       "          3,\n",
       "          8,\n",
       "          11,\n",
       "          13\n",
       "        ],\n",
       "        \"token_logprobs\": [\n",
       "          null,\n",
       "          -10.322586,\n",
       "          -7.9263377,\n",
       "          -1.5632153,\n",
       "          -3.7549405\n",
       "        ],\n",
       "        \"tokens\": [\n",
       "          \"Say\",\n",
       "          \" this\",\n",
       "          \" is\",\n",
       "          \" a\",\n",
       "          \" test\"\n",
       "        ],\n",
       "        \"top_logprobs\": [\n",
       "          null,\n",
       "          {\n",
       "            \"\\n\": -0.5398547\n",
       "          },\n",
       "          {\n",
       "            \" question\": -0.4790101\n",
       "          },\n",
       "          {\n",
       "            \" your\": -1.5118054\n",
       "          },\n",
       "          {\n",
       "            \" question\": -0.81148016\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"text\": \"Say this is a test\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1673438874,\n",
       "  \"id\": \"cmpl-6XUBW3t50Lsy6IUdthIFYT04SXwMW\",\n",
       "  \"model\": \"text-ada-001\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 5\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai_integration\n",
    "import openai\n",
    "\n",
    "openai.Completion.create(\n",
    "  model=\"text-ada-001\",\n",
    "  prompt=\"Say this is a test\",\n",
    "  max_tokens=0,\n",
    "  temperature=0,\n",
    "  logprobs=1,\n",
    "  echo=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, n):\n",
    "        self.tokens = [[] for _ in range(n)]\n",
    "        self.logprobs = [[] for _ in range(n)]\n",
    "        self.response_data = [[] for _ in range(n)]\n",
    "\n",
    "        self.n = n\n",
    "        self.ctr = 0\n",
    "\n",
    "    def advance_stream_iter(self):\n",
    "        for i in range(self.n):\n",
    "            self.tokens[i] += [\"token\" + str(self.ctr)]\n",
    "            self.logprobs[i] += [\"logprob\" + str(self.ctr)]\n",
    "            self.response_data[i] += [\"response_data\" + str(self.ctr)]\n",
    "        self.ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAITokenResult(token='token11', logprob='logprob11', data='response_data11')\n",
      "OpenAITokenResult(token='token12', logprob='logprob12', data='response_data12')\n",
      "OpenAITokenResult(token='token13', logprob='logprob13', data='response_data13')\n",
      "OpenAITokenResult(token='token14', logprob='logprob14', data='response_data14')\n",
      "OpenAITokenResult(token='token15', logprob='logprob15', data='response_data15')\n",
      "OpenAITokenResult(token='token16', logprob='logprob16', data='response_data16')\n",
      "OpenAITokenResult(token='token17', logprob='logprob17', data='response_data17')\n",
      "OpenAITokenResult(token='token18', logprob='logprob18', data='response_data18')\n",
      "OpenAITokenResult(token='token19', logprob='logprob19', data='response_data19')\n",
      "OpenAITokenResult(token='token20', logprob='logprob20', data='response_data20')\n"
     ]
    }
   ],
   "source": [
    "b = Buffer(2)\n",
    "r = SequenceResult(b, 0)[10:][1:]\n",
    "for i in range(10):\n",
    "    print(r[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "languagemodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92122517a1dbb03a2e7dfc54de9c6e27579d45734a0d74779e95546fb68a6d62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
