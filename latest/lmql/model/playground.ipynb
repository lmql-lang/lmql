{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "re_hex_color_prefix = re.compile(r\"[0-9a-fA-F]{1,6}\")\n",
    "\n",
    "# filter tokens only for tokens that match the above regex\n",
    "allowed_tokens = [i for i,token in enumerate(tokens) if re_hex_color_prefix.fullmatch(token)]\n",
    "mask = torch.zeros(len(tokens), dtype=torch.long)\n",
    "mask[allowed_tokens] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 6), match='FFAAAA'>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re_hex_color_prefix.match(\"00\") \n",
    "res = re_hex_color_prefix.match(\"FFAAAA\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this tutorial you will learn about hex encoding of colors.!!!!!!!!!!. For example, the hex code for red is #FF0000. For green the hex code is different:!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "class Prompter:\n",
    "    def __init__(self, seq):\n",
    "        self.seq = seq\n",
    "        tokenizer_result = tokenizer(seq)\n",
    "        self.input_ids = torch.tensor(tokenizer_result[\"input_ids\"])\n",
    "        self.attention_mask = torch.tensor(tokenizer_result[\"attention_mask\"])\n",
    "\n",
    "    def step(self, mask=None):\n",
    "        res = model.forward(input_ids=self.input_ids, attention_mask=self.attention_mask)\n",
    "        logits = res.logits[-1]\n",
    "        # if mask is not None: logits[mask] = 0\n",
    "        next_token_id = logits[-1].argmax()\n",
    "        self.input_ids = torch.cat((self.input_ids, torch.tensor([next_token_id]))).to(torch.long)\n",
    "        self.attention_mask = torch.cat((self.attention_mask, torch.tensor([1])))\n",
    "        self.seq = tokenizer.decode(self.input_ids.tolist())\n",
    "\n",
    "    def steps(self, n, until=None, mask=None):\n",
    "        for i in range(n): \n",
    "            self.step(mask=mask)\n",
    "            if until is not None and self.seq.endswith(until): \n",
    "                break\n",
    "\n",
    "    def result(self):\n",
    "        return self.seq\n",
    "\n",
    "    def prompt(self, s):\n",
    "        self.seq += s\n",
    "        tokenizer_result = tokenizer(self.seq)\n",
    "        self.input_ids = torch.tensor(tokenizer_result[\"input_ids\"])\n",
    "        self.attention_mask = torch.tensor(tokenizer_result[\"attention_mask\"])\n",
    "\n",
    "p = Prompter(\"In this tutorial you will learn about hex encoding of colors.\")\n",
    "p.steps(10)\n",
    "p.prompt(\". For example, the hex code for red is #FF0000. For green the hex code is different: \")\n",
    "p.steps(12, until=\".\")\n",
    "\n",
    "print(p.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('languagemodels')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92122517a1dbb03a2e7dfc54de9c6e27579d45734a0d74779e95546fb68a6d62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
